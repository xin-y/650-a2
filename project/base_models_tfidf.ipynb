{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/jiangruiyin/Desktop/proj/data_cleaned(1).csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path, header=None, names=['lyrics', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>touch me turn me on and burn me down   your li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>well i dont give a damn that your cars on fire...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i saw you starin at each other i saw your eyes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>your cruel device your blood like ice one look...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>stretch the bones over my skin stretch the ski...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2459</td>\n",
       "      <td>haces muy mal en elevar mi tensión en aplastar...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>cierro los ojos sin mirar atrás las cosas buen...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2461</td>\n",
       "      <td>una palomita blanca de piquito colorado ayer y...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2462</td>\n",
       "      <td>sólo una palabra se hubiera llevado el dolor c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2463</td>\n",
       "      <td>lover please please come back dont take a trai...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 lyrics  label\n",
       "0     touch me turn me on and burn me down   your li...      0\n",
       "1     well i dont give a damn that your cars on fire...      0\n",
       "2     i saw you starin at each other i saw your eyes...      0\n",
       "3     your cruel device your blood like ice one look...      0\n",
       "4     stretch the bones over my skin stretch the ski...      0\n",
       "...                                                 ...    ...\n",
       "2459  haces muy mal en elevar mi tensión en aplastar...      3\n",
       "2460  cierro los ojos sin mirar atrás las cosas buen...      3\n",
       "2461  una palomita blanca de piquito colorado ayer y...      3\n",
       "2462  sólo una palabra se hubiera llevado el dolor c...      3\n",
       "2463  lover please please come back dont take a trai...      3\n",
       "\n",
       "[2464 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.iloc[:,1]\n",
    "lyrics = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[2462]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sólo una palabra se hubiera llevado el dolor con el beso amargo de aquel licor hubiera bastado mi amor sólo una mentira se viene conmigo a pasear sentirme querida en aquel abrazo en el mar  con el vestido azul que un día conociste me marcho sin saber si me besaste antes de irte te di mi corazón y tú lo regalaste te di todo el amor que pude darte y me robaste he rasgado mi vestido con una copa de vino hoy tu amor corta como el cristal  en el cielo hay playas donde ves la vida pasar donde los recuerdos no hacen llorar vienen muy despacio y se van sólo una caricia me hubiera ayudado a olvidar que no eran mis labios los que ahora te hacen soñar  con el vestido azul que un día conociste me marcho sin saber si me besaste antes de irte te di mi corazón y tú lo regalaste te di todo el amor que pude darte y me robaste he rasgado mi vestido con una copa de vino hoy tu amor corta como el cristal buena suerte en tu camino yo ya tengo mi destino con mi sangre escribo este final'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics[2462]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       touch me turn me on and burn me down   your li...\n",
       "1       well i dont give a damn that your cars on fire...\n",
       "2       i saw you starin at each other i saw your eyes...\n",
       "3       your cruel device your blood like ice one look...\n",
       "4       stretch the bones over my skin stretch the ski...\n",
       "                              ...                        \n",
       "2459    haces muy mal en elevar mi tensión en aplastar...\n",
       "2460    cierro los ojos sin mirar atrás las cosas buen...\n",
       "2461    una palomita blanca de piquito colorado ayer y...\n",
       "2462    sólo una palabra se hubiera llevado el dolor c...\n",
       "2463    lover please please come back dont take a trai...\n",
       "Name: lyrics, Length: 2464, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lyrics, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1375    listen to the girl as she takes on half the wo...\n",
       "903     have yourself a merry little christmas let you...\n",
       "1939    the show is over partys just begun im high ton...\n",
       "1325    one day well walk in the sun  my name is verno...\n",
       "1995    mercy dont think shes pretty no more starin at...\n",
       "                              ...                        \n",
       "1638    ive seen god in the sun ive seen god in the st...\n",
       "1095    i dont want another heartbreak i dont need ano...\n",
       "1130    id gladly walk across the desert with no shoes...\n",
       "1294    our god is an awesome god he reigns from heave...\n",
       "860     i dont want you anymore cause you took my joy ...\n",
       "Name: lyrics, Length: 1971, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='ignore',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True,\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                strip_accents=None, sublinear_tf=False,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# stopwords\n",
    "stop_words_EN = stopwords.words('english')\n",
    "stop_words_SP = stopwords.words('spanish')\n",
    "stop_words = stop_words_EN + stop_words_SP\n",
    "# TF-IDF\n",
    "tf_transfomer = TfidfVectorizer(stop_words=stop_words, decode_error='ignore')\n",
    "tf_transfomer.fit(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts_tf = tf_transfomer.transform(X_train)\n",
    "X_test_counts_tf = tf_transfomer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1971x14817 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 90867 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<493x14817 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 22506 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paras Tuning of base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "seed = 42\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.7843562528841717 ; alpha: {'alpha': 0.05}\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "param_grid = {}\n",
    "param_grid['alpha'] = [0.001,0.01,0.05,0.1,0.5,1,5]\n",
    "model = MultinomialNB()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, scoring = scoring, cv = kfold)\n",
    "grid_result = grid.fit(X = X_train_counts_tf, y = y_train)\n",
    "print('Best accuracy: %s ; alpha: %s' % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.9254037840332255 ; C: {'C': 15}\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "param_grid = {}\n",
    "param_grid['C'] = [0.1,5,13,15]\n",
    "model = LogisticRegression()\n",
    "kfold = KFold(n_splits = num_folds, random_state = seed)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, scoring = scoring, cv = kfold)\n",
    "grid_result = grid.fit(X = X_train_counts_tf, y = y_train)\n",
    "print('Best accuracy: %s ; C: %s' % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.9345357124544942 ; C: {'C': 10, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "param_grid = {}\n",
    "param_grid['C'] = [1,10,20]\n",
    "param_grid['kernel'] = ['rbf','linear']\n",
    "model = svm.SVC(gamma = 'auto')\n",
    "kfold = KFold(n_splits = num_folds,random_state = seed)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, scoring = scoring, cv = kfold)\n",
    "grid_result = grid.fit(X = X_train_counts_tf, y = y_train)\n",
    "print('Best accuracy: %s ; C: %s' % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8985801217038539"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoost\n",
    "clf=AdaBoostClassifier(base_estimator = LogisticRegression(C=15), algorithm='SAMME', n_estimators=300, learning_rate=0.8)\n",
    "clf.fit(X_train_counts_tf, y_train).score(X_test_counts_tf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learners = [\n",
    "                 ('clf_1', LogisticRegression(C = 15)),\n",
    "                 ('clf_2', svm.SVC(gamma = 'auto',C = 10, kernel = 'linear' )) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9249492900608519"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stack\n",
    "stack = StackingClassifier(estimators = base_learners, final_estimator = LogisticRegression())\n",
    "stack.fit(X_train_counts_tf, y_train).score(X_test_counts_tf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9310344827586207"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stack\n",
    "stack_ = StackingClassifier(estimators = base_learners, final_estimator = svm.SVC())\n",
    "stack_.fit(X_train_counts_tf, y_train).score(X_test_counts_tf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

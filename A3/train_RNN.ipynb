{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ftrain_RNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDs63-kISrUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR-U-fpHDcIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c900329e-b811-4ec3-d0f1-cb12cd89206e"
      },
      "source": [
        "%pwd\n",
        "%cd /content/drive/My Drive/assignment3/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/assignment3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfYmkvxyArLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data = pd.read_csv('./data/q2_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fPhmq-zqSIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# values = data.values\n",
        "\n",
        "# targets = []\n",
        "# features = []\n",
        "# days = 3\n",
        "# for i in range(len(values)-days):\n",
        "#   targets.append(values[i][1].replace('$',''))\n",
        "#   feature=[]\n",
        "#   for j in range(2,6):\n",
        "#     for k in range(0,days):\n",
        "#       feature.append(values[i+k+1][j])\n",
        "\n",
        "#   features.append(feature)\n",
        "# features = np.reshape(features,(len(targets),days*4))\n",
        "# targets = np.reshape(targets,(len(targets),1))\n",
        "# targets.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i36UNhSjQGTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# my_dataset = np.c_[features,targets]\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(features, targets, test_size=0.3,random_state=42)\n",
        "# train_dataset = np.c_[x_train,y_train]\n",
        "# test_dataset = np.c_[x_test,y_test]\n",
        "# print(train_dataset.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29PmcHh8S7gl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1bf27d30-0e7e-4af3-c18d-0258273602bc"
      },
      "source": [
        "# with open('./data/train_data_RNN.csv', 'wb') as f:\n",
        "#   np.savetxt(f, train_dataset,fmt='%s',delimiter=',')\n",
        "# f.close"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function BufferedWriter.close>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sC-F7GRhXTMZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "02d263e5-74ef-4e09-a9e3-c11e04f5e790"
      },
      "source": [
        "# with open('./data/test_data_RNN.csv', 'wb') as f:\n",
        "  \n",
        "#   np.savetxt(f, test_dataset,fmt='%s',delimiter=',')\n",
        "# f.close"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function BufferedWriter.close>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceA2IiFKZogw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.loadtxt('./data/train_data_RNN.csv',delimiter=',',skiprows=0)\n",
        "test_data = np.loadtxt('./data/test_data_RNN.csv',delimiter=',',skiprows=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79JD-jq9LrJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train = train_data[:, :-1]\n",
        "y_train = train_data[:,-1]\n",
        "x_test = test_data[:, :-1]\n",
        "y_test = test_data[:,-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYJcVW89sfhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.fit_transform(x_test)\n",
        "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
        "x_train, x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfIbqsHEyT4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create model\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(50,input_shape=(x_train.shape[1],1),return_sequences=True))\n",
        "  model.add(LSTM(100))\n",
        "  model.add(Dense(1,activation='linear'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxTSAEkwuwtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSC-FCgBvLN4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0752d20e-92af-423a-c7b3-2e83b8ae1d79"
      },
      "source": [
        "#reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1,patience=3)\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['mae'])                                 \n",
        "history = model.fit(x_train,y_train, epochs=600,validation_data=[x_val,y_val])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 703 samples, validate on 176 samples\n",
            "Epoch 1/600\n",
            "703/703 [==============================] - 2s 2ms/step - loss: 32727.4474 - mae: 169.4063 - val_loss: 33614.1928 - val_mae: 170.9934\n",
            "Epoch 2/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 29228.3465 - mae: 158.6803 - val_loss: 31396.1747 - val_mae: 164.2782\n",
            "Epoch 3/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 27936.5827 - mae: 154.5360 - val_loss: 30461.6825 - val_mae: 161.4069\n",
            "Epoch 4/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 27118.9216 - mae: 151.8712 - val_loss: 29654.6278 - val_mae: 158.8871\n",
            "Epoch 5/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 26384.7869 - mae: 149.4129 - val_loss: 28899.7401 - val_mae: 156.4935\n",
            "Epoch 6/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 25689.0800 - mae: 147.0870 - val_loss: 28190.1559 - val_mae: 154.2097\n",
            "Epoch 7/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25029.5366 - mae: 144.8277 - val_loss: 27509.7058 - val_mae: 151.9874\n",
            "Epoch 8/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24398.4224 - mae: 142.6156 - val_loss: 26848.3026 - val_mae: 149.7957\n",
            "Epoch 9/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 23782.9756 - mae: 140.4637 - val_loss: 26214.2278 - val_mae: 147.6641\n",
            "Epoch 10/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23189.2415 - mae: 138.3414 - val_loss: 25592.2775 - val_mae: 145.5429\n",
            "Epoch 11/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 22597.5484 - mae: 136.1851 - val_loss: 24961.0526 - val_mae: 143.3580\n",
            "Epoch 12/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 22009.9390 - mae: 134.0119 - val_loss: 24348.5842 - val_mae: 141.2057\n",
            "Epoch 13/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 21443.9092 - mae: 131.8698 - val_loss: 23753.4382 - val_mae: 139.0823\n",
            "Epoch 14/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 20893.8864 - mae: 129.7708 - val_loss: 23179.0902 - val_mae: 137.0020\n",
            "Epoch 15/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 20361.5103 - mae: 127.7062 - val_loss: 22622.2344 - val_mae: 134.9544\n",
            "Epoch 16/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 19847.0546 - mae: 125.6609 - val_loss: 22076.4771 - val_mae: 132.9170\n",
            "Epoch 17/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 19342.0498 - mae: 123.6490 - val_loss: 21552.2802 - val_mae: 130.9303\n",
            "Epoch 18/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 18855.6040 - mae: 121.6645 - val_loss: 21037.3640 - val_mae: 128.9489\n",
            "Epoch 19/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 18380.1217 - mae: 119.6966 - val_loss: 20536.4585 - val_mae: 126.9918\n",
            "Epoch 20/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 17916.8438 - mae: 117.7531 - val_loss: 20050.2003 - val_mae: 125.0626\n",
            "Epoch 21/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 17467.6340 - mae: 115.8256 - val_loss: 19574.2160 - val_mae: 123.1449\n",
            "Epoch 22/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 17031.6187 - mae: 113.9057 - val_loss: 19105.7180 - val_mae: 121.2278\n",
            "Epoch 23/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 16601.9487 - mae: 112.0153 - val_loss: 18656.3152 - val_mae: 119.3599\n",
            "Epoch 24/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 16187.2343 - mae: 110.1594 - val_loss: 18216.5891 - val_mae: 117.5034\n",
            "Epoch 25/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 15783.7924 - mae: 108.3036 - val_loss: 17786.0967 - val_mae: 115.6571\n",
            "Epoch 26/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 15388.7255 - mae: 106.4727 - val_loss: 17369.9980 - val_mae: 113.8440\n",
            "Epoch 27/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 15006.7573 - mae: 104.6663 - val_loss: 16961.3353 - val_mae: 112.0348\n",
            "Epoch 28/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 14633.3075 - mae: 102.8638 - val_loss: 16564.4757 - val_mae: 110.2494\n",
            "Epoch 29/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 14271.3143 - mae: 101.0861 - val_loss: 16175.4664 - val_mae: 108.4709\n",
            "Epoch 30/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 13916.5677 - mae: 99.3207 - val_loss: 15800.2928 - val_mae: 106.7275\n",
            "Epoch 31/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 13574.2598 - mae: 97.5790 - val_loss: 15431.5648 - val_mae: 104.9858\n",
            "Epoch 32/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 13240.9258 - mae: 95.8338 - val_loss: 15070.8238 - val_mae: 103.2535\n",
            "Epoch 33/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 12915.8125 - mae: 94.1121 - val_loss: 14720.2094 - val_mae: 101.5415\n",
            "Epoch 34/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 12595.6877 - mae: 92.4336 - val_loss: 14380.0966 - val_mae: 99.8527\n",
            "Epoch 35/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 12277.9899 - mae: 90.7041 - val_loss: 14034.3327 - val_mae: 98.1060\n",
            "Epoch 36/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 11965.3210 - mae: 88.9640 - val_loss: 13699.3326 - val_mae: 96.3836\n",
            "Epoch 37/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 11665.6605 - mae: 87.2438 - val_loss: 13372.0382 - val_mae: 94.6705\n",
            "Epoch 38/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 11372.3832 - mae: 85.5680 - val_loss: 13061.3887 - val_mae: 93.0153\n",
            "Epoch 39/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 11092.8032 - mae: 83.9068 - val_loss: 12757.1032 - val_mae: 91.3650\n",
            "Epoch 40/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 10821.8461 - mae: 82.2571 - val_loss: 12460.4488 - val_mae: 89.7269\n",
            "Epoch 41/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 10558.1203 - mae: 80.6391 - val_loss: 12174.6312 - val_mae: 88.1286\n",
            "Epoch 42/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 10302.8980 - mae: 79.0523 - val_loss: 11899.0277 - val_mae: 86.5686\n",
            "Epoch 43/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 10056.8540 - mae: 77.5071 - val_loss: 11630.5716 - val_mae: 85.0212\n",
            "Epoch 44/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 9818.0398 - mae: 76.0178 - val_loss: 11370.7469 - val_mae: 83.4968\n",
            "Epoch 45/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 9587.1107 - mae: 74.6180 - val_loss: 11118.6072 - val_mae: 82.0464\n",
            "Epoch 46/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 9363.1685 - mae: 73.2705 - val_loss: 10875.0127 - val_mae: 80.6812\n",
            "Epoch 47/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 9147.2389 - mae: 71.9861 - val_loss: 10637.5419 - val_mae: 79.3618\n",
            "Epoch 48/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 8938.5387 - mae: 70.7515 - val_loss: 10405.7501 - val_mae: 78.0739\n",
            "Epoch 49/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 8733.1043 - mae: 69.5672 - val_loss: 10187.9534 - val_mae: 76.8481\n",
            "Epoch 50/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 8541.3228 - mae: 68.4118 - val_loss: 9966.5069 - val_mae: 75.5812\n",
            "Epoch 51/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 8349.8905 - mae: 67.3009 - val_loss: 9756.8872 - val_mae: 74.3792\n",
            "Epoch 52/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 8166.0283 - mae: 66.2239 - val_loss: 9555.7422 - val_mae: 73.2273\n",
            "Epoch 53/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 7989.8127 - mae: 65.2265 - val_loss: 9359.2785 - val_mae: 72.1142\n",
            "Epoch 54/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 7820.1983 - mae: 64.2998 - val_loss: 9166.0245 - val_mae: 71.0316\n",
            "Epoch 55/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 7653.5966 - mae: 63.4515 - val_loss: 8983.2048 - val_mae: 70.0325\n",
            "Epoch 56/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 7495.1771 - mae: 62.6692 - val_loss: 8804.4068 - val_mae: 69.0888\n",
            "Epoch 57/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 7341.0133 - mae: 61.9364 - val_loss: 8632.9747 - val_mae: 68.2523\n",
            "Epoch 58/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 7193.5541 - mae: 61.2667 - val_loss: 8465.2110 - val_mae: 67.4780\n",
            "Epoch 59/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 7050.1181 - mae: 60.6670 - val_loss: 8304.6776 - val_mae: 66.7631\n",
            "Epoch 60/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 6912.1210 - mae: 60.1351 - val_loss: 8150.4248 - val_mae: 66.1043\n",
            "Epoch 61/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 6781.6839 - mae: 59.6333 - val_loss: 7995.9616 - val_mae: 65.4887\n",
            "Epoch 62/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 6652.6026 - mae: 59.1738 - val_loss: 7850.8613 - val_mae: 64.9184\n",
            "Epoch 63/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 6529.9087 - mae: 58.7286 - val_loss: 7710.0559 - val_mae: 64.3610\n",
            "Epoch 64/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 6411.0845 - mae: 58.3316 - val_loss: 7575.6831 - val_mae: 63.8370\n",
            "Epoch 65/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 6296.4014 - mae: 57.9382 - val_loss: 7448.6880 - val_mae: 63.3318\n",
            "Epoch 66/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 6189.1983 - mae: 57.5447 - val_loss: 7319.8808 - val_mae: 62.8084\n",
            "Epoch 67/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 6084.0193 - mae: 57.1553 - val_loss: 7195.9364 - val_mae: 62.2938\n",
            "Epoch 68/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 5982.6031 - mae: 56.7735 - val_loss: 7077.7608 - val_mae: 61.7923\n",
            "Epoch 69/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 5885.0383 - mae: 56.4060 - val_loss: 6965.9247 - val_mae: 61.3114\n",
            "Epoch 70/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 5792.4128 - mae: 56.0474 - val_loss: 6857.3634 - val_mae: 60.8427\n",
            "Epoch 71/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 5703.6813 - mae: 55.6965 - val_loss: 6751.6502 - val_mae: 60.3763\n",
            "Epoch 72/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 5617.5889 - mae: 55.3569 - val_loss: 6651.6425 - val_mae: 59.9253\n",
            "Epoch 73/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 5536.7105 - mae: 55.0382 - val_loss: 6552.8568 - val_mae: 59.4698\n",
            "Epoch 74/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 5458.0138 - mae: 54.6986 - val_loss: 6458.4929 - val_mae: 59.0247\n",
            "Epoch 75/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 5383.3225 - mae: 54.4135 - val_loss: 6367.3682 - val_mae: 58.5851\n",
            "Epoch 76/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 5311.9375 - mae: 54.1146 - val_loss: 6279.2503 - val_mae: 58.1578\n",
            "Epoch 77/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 5243.1183 - mae: 53.8239 - val_loss: 6195.7041 - val_mae: 57.7541\n",
            "Epoch 78/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 5175.7089 - mae: 53.5178 - val_loss: 6120.8319 - val_mae: 57.3878\n",
            "Epoch 79/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 5114.5784 - mae: 53.2487 - val_loss: 6044.7432 - val_mae: 57.0073\n",
            "Epoch 80/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 5055.9136 - mae: 52.9849 - val_loss: 5968.7245 - val_mae: 56.6380\n",
            "Epoch 81/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4997.9228 - mae: 52.7362 - val_loss: 5898.6531 - val_mae: 56.2934\n",
            "Epoch 82/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4943.5215 - mae: 52.4969 - val_loss: 5832.0089 - val_mae: 55.9775\n",
            "Epoch 83/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4892.4880 - mae: 52.2654 - val_loss: 5765.9925 - val_mae: 55.6692\n",
            "Epoch 84/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4842.9777 - mae: 52.0389 - val_loss: 5703.5547 - val_mae: 55.3799\n",
            "Epoch 85/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4796.0195 - mae: 51.8297 - val_loss: 5644.6462 - val_mae: 55.1236\n",
            "Epoch 86/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4751.0811 - mae: 51.6121 - val_loss: 5589.1078 - val_mae: 54.8966\n",
            "Epoch 87/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4708.9047 - mae: 51.4247 - val_loss: 5535.5070 - val_mae: 54.6761\n",
            "Epoch 88/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4670.2494 - mae: 51.2572 - val_loss: 5479.8195 - val_mae: 54.4605\n",
            "Epoch 89/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4630.7196 - mae: 51.0814 - val_loss: 5430.4674 - val_mae: 54.2698\n",
            "Epoch 90/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4594.1195 - mae: 50.9196 - val_loss: 5384.6396 - val_mae: 54.0884\n",
            "Epoch 91/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4560.8021 - mae: 50.7811 - val_loss: 5337.9332 - val_mae: 53.8991\n",
            "Epoch 92/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4528.7001 - mae: 50.6358 - val_loss: 5292.6986 - val_mae: 53.7113\n",
            "Epoch 93/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4496.7160 - mae: 50.5033 - val_loss: 5253.3062 - val_mae: 53.5487\n",
            "Epoch 94/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4468.3495 - mae: 50.3765 - val_loss: 5213.4482 - val_mae: 53.3909\n",
            "Epoch 95/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4440.7620 - mae: 50.2584 - val_loss: 5176.0440 - val_mae: 53.2392\n",
            "Epoch 96/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4414.9211 - mae: 50.1447 - val_loss: 5140.3050 - val_mae: 53.0918\n",
            "Epoch 97/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4391.0308 - mae: 50.0473 - val_loss: 5104.2551 - val_mae: 52.9497\n",
            "Epoch 98/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4367.0756 - mae: 49.9370 - val_loss: 5072.8642 - val_mae: 52.8377\n",
            "Epoch 99/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4346.6469 - mae: 49.8613 - val_loss: 5039.0860 - val_mae: 52.7256\n",
            "Epoch 100/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4325.6530 - mae: 49.7879 - val_loss: 5008.8834 - val_mae: 52.6412\n",
            "Epoch 101/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4306.0884 - mae: 49.7041 - val_loss: 4981.5571 - val_mae: 52.5700\n",
            "Epoch 102/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4288.5843 - mae: 49.6456 - val_loss: 4954.3022 - val_mae: 52.4990\n",
            "Epoch 103/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4271.1771 - mae: 49.5917 - val_loss: 4929.6477 - val_mae: 52.4418\n",
            "Epoch 104/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4255.7202 - mae: 49.5481 - val_loss: 4905.0359 - val_mae: 52.3898\n",
            "Epoch 105/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4240.6244 - mae: 49.5117 - val_loss: 4882.3842 - val_mae: 52.3450\n",
            "Epoch 106/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4227.2796 - mae: 49.4902 - val_loss: 4859.4861 - val_mae: 52.3026\n",
            "Epoch 107/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4213.7742 - mae: 49.4594 - val_loss: 4838.9062 - val_mae: 52.2636\n",
            "Epoch 108/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4201.4256 - mae: 49.4286 - val_loss: 4819.8039 - val_mae: 52.2305\n",
            "Epoch 109/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4189.9511 - mae: 49.4114 - val_loss: 4801.8959 - val_mae: 52.2001\n",
            "Epoch 110/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4179.5349 - mae: 49.3814 - val_loss: 4784.0555 - val_mae: 52.1736\n",
            "Epoch 111/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4169.7345 - mae: 49.3749 - val_loss: 4766.7754 - val_mae: 52.1530\n",
            "Epoch 112/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4160.8652 - mae: 49.3681 - val_loss: 4749.1692 - val_mae: 52.1316\n",
            "Epoch 113/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4151.3287 - mae: 49.3482 - val_loss: 4735.4918 - val_mae: 52.1146\n",
            "Epoch 114/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4143.4982 - mae: 49.3359 - val_loss: 4722.2293 - val_mae: 52.0977\n",
            "Epoch 115/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4136.6273 - mae: 49.3387 - val_loss: 4706.9073 - val_mae: 52.0777\n",
            "Epoch 116/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4128.9924 - mae: 49.3272 - val_loss: 4695.5563 - val_mae: 52.0626\n",
            "Epoch 117/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4122.8847 - mae: 49.3232 - val_loss: 4683.0708 - val_mae: 52.0457\n",
            "Epoch 118/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4117.0879 - mae: 49.3275 - val_loss: 4670.5179 - val_mae: 52.0307\n",
            "Epoch 119/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4111.3328 - mae: 49.3248 - val_loss: 4660.0237 - val_mae: 52.0195\n",
            "Epoch 120/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4106.6523 - mae: 49.3277 - val_loss: 4648.3359 - val_mae: 52.0067\n",
            "Epoch 121/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4101.5097 - mae: 49.3273 - val_loss: 4638.9250 - val_mae: 51.9962\n",
            "Epoch 122/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4097.3164 - mae: 49.3327 - val_loss: 4629.5377 - val_mae: 51.9856\n",
            "Epoch 123/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4093.7327 - mae: 49.3408 - val_loss: 4619.8255 - val_mae: 51.9743\n",
            "Epoch 124/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4089.3828 - mae: 49.3383 - val_loss: 4613.7427 - val_mae: 51.9671\n",
            "Epoch 125/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4086.3099 - mae: 49.3404 - val_loss: 4605.6999 - val_mae: 51.9591\n",
            "Epoch 126/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4084.0547 - mae: 49.3541 - val_loss: 4595.7569 - val_mae: 51.9510\n",
            "Epoch 127/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4080.1344 - mae: 49.3522 - val_loss: 4591.0364 - val_mae: 51.9470\n",
            "Epoch 128/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4077.8333 - mae: 49.3611 - val_loss: 4584.0965 - val_mae: 51.9411\n",
            "Epoch 129/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4075.4112 - mae: 49.3704 - val_loss: 4577.4913 - val_mae: 51.9354\n",
            "Epoch 130/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4073.1779 - mae: 49.3718 - val_loss: 4572.1157 - val_mae: 51.9306\n",
            "Epoch 131/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4071.3139 - mae: 49.3759 - val_loss: 4566.6060 - val_mae: 51.9257\n",
            "Epoch 132/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4069.4173 - mae: 49.3852 - val_loss: 4561.1474 - val_mae: 51.9207\n",
            "Epoch 133/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4067.8381 - mae: 49.3941 - val_loss: 4555.4432 - val_mae: 51.9153\n",
            "Epoch 134/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4066.1066 - mae: 49.3988 - val_loss: 4551.3377 - val_mae: 51.9115\n",
            "Epoch 135/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4064.8457 - mae: 49.4030 - val_loss: 4546.7869 - val_mae: 51.9071\n",
            "Epoch 136/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4063.5259 - mae: 49.4078 - val_loss: 4542.7938 - val_mae: 51.9043\n",
            "Epoch 137/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4062.4529 - mae: 49.4183 - val_loss: 4539.0852 - val_mae: 51.9024\n",
            "Epoch 138/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4061.3876 - mae: 49.4217 - val_loss: 4535.2346 - val_mae: 51.9005\n",
            "Epoch 139/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4060.4658 - mae: 49.4290 - val_loss: 4532.3020 - val_mae: 51.8990\n",
            "Epoch 140/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4059.7652 - mae: 49.4380 - val_loss: 4527.6624 - val_mae: 51.8966\n",
            "Epoch 141/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4059.0034 - mae: 49.4435 - val_loss: 4526.1982 - val_mae: 51.8958\n",
            "Epoch 142/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4058.4186 - mae: 49.4540 - val_loss: 4522.1940 - val_mae: 51.8937\n",
            "Epoch 143/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4057.5749 - mae: 49.4594 - val_loss: 4519.0312 - val_mae: 51.8920\n",
            "Epoch 144/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4057.0541 - mae: 49.4692 - val_loss: 4516.2164 - val_mae: 51.8910\n",
            "Epoch 145/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4056.5165 - mae: 49.4759 - val_loss: 4514.2211 - val_mae: 51.8910\n",
            "Epoch 146/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4056.1311 - mae: 49.4829 - val_loss: 4511.6410 - val_mae: 51.8910\n",
            "Epoch 147/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4055.7287 - mae: 49.4914 - val_loss: 4509.8363 - val_mae: 51.8910\n",
            "Epoch 148/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4055.3396 - mae: 49.4947 - val_loss: 4507.9098 - val_mae: 51.8910\n",
            "Epoch 149/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4055.1076 - mae: 49.5027 - val_loss: 4505.5736 - val_mae: 51.8912\n",
            "Epoch 150/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4054.7250 - mae: 49.5094 - val_loss: 4504.0034 - val_mae: 51.8922\n",
            "Epoch 151/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4054.5477 - mae: 49.5199 - val_loss: 4501.8271 - val_mae: 51.8934\n",
            "Epoch 152/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4054.1769 - mae: 49.5233 - val_loss: 4501.0620 - val_mae: 51.8939\n",
            "Epoch 153/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4054.1407 - mae: 49.5284 - val_loss: 4499.3649 - val_mae: 51.8949\n",
            "Epoch 154/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4054.1463 - mae: 49.5320 - val_loss: 4498.9774 - val_mae: 51.8951\n",
            "Epoch 155/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4053.7617 - mae: 49.5345 - val_loss: 4497.7269 - val_mae: 51.8959\n",
            "Epoch 156/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.5992 - mae: 49.5416 - val_loss: 4496.0502 - val_mae: 51.8969\n",
            "Epoch 157/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.6022 - mae: 49.5525 - val_loss: 4493.5586 - val_mae: 51.8984\n",
            "Epoch 158/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.3177 - mae: 49.5584 - val_loss: 4492.6296 - val_mae: 51.8990\n",
            "Epoch 159/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.2893 - mae: 49.5605 - val_loss: 4491.7545 - val_mae: 51.8996\n",
            "Epoch 160/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.3712 - mae: 49.5722 - val_loss: 4489.7923 - val_mae: 51.9008\n",
            "Epoch 161/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4053.3926 - mae: 49.5691 - val_loss: 4491.5504 - val_mae: 51.8997\n",
            "Epoch 162/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.4441 - mae: 49.5768 - val_loss: 4489.0509 - val_mae: 51.9013\n",
            "Epoch 163/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.9583 - mae: 49.5753 - val_loss: 4488.6687 - val_mae: 51.9015\n",
            "Epoch 164/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9769 - mae: 49.5807 - val_loss: 4487.4019 - val_mae: 51.9023\n",
            "Epoch 165/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4053.0690 - mae: 49.5883 - val_loss: 4486.6798 - val_mae: 51.9028\n",
            "Epoch 166/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9246 - mae: 49.5846 - val_loss: 4486.5428 - val_mae: 51.9029\n",
            "Epoch 167/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.1068 - mae: 49.5950 - val_loss: 4484.7720 - val_mae: 51.9040\n",
            "Epoch 168/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7534 - mae: 49.5939 - val_loss: 4485.6017 - val_mae: 51.9035\n",
            "Epoch 169/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.9639 - mae: 49.5904 - val_loss: 4486.3528 - val_mae: 51.9030\n",
            "Epoch 170/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.9845 - mae: 49.5957 - val_loss: 4483.9918 - val_mae: 51.9045\n",
            "Epoch 171/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.8347 - mae: 49.6034 - val_loss: 4483.2510 - val_mae: 51.9050\n",
            "Epoch 172/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7007 - mae: 49.6000 - val_loss: 4484.0044 - val_mae: 51.9045\n",
            "Epoch 173/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4053.0831 - mae: 49.6032 - val_loss: 4484.5154 - val_mae: 51.9042\n",
            "Epoch 174/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9840 - mae: 49.6056 - val_loss: 4482.6580 - val_mae: 51.9054\n",
            "Epoch 175/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9276 - mae: 49.5995 - val_loss: 4484.0414 - val_mae: 51.9045\n",
            "Epoch 176/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6656 - mae: 49.6040 - val_loss: 4482.3278 - val_mae: 51.9057\n",
            "Epoch 177/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6859 - mae: 49.6097 - val_loss: 4482.2925 - val_mae: 51.9057\n",
            "Epoch 178/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.4606 - mae: 49.6249 - val_loss: 4479.6386 - val_mae: 51.9092\n",
            "Epoch 179/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.5407 - mae: 49.6183 - val_loss: 4481.0678 - val_mae: 51.9073\n",
            "Epoch 180/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9707 - mae: 49.6086 - val_loss: 4482.0490 - val_mae: 51.9060\n",
            "Epoch 181/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6495 - mae: 49.6086 - val_loss: 4481.9001 - val_mae: 51.9062\n",
            "Epoch 182/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.0099 - mae: 49.6157 - val_loss: 4482.0031 - val_mae: 51.9061\n",
            "Epoch 183/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6748 - mae: 49.6114 - val_loss: 4481.7114 - val_mae: 51.9064\n",
            "Epoch 184/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.9091 - mae: 49.6108 - val_loss: 4481.5913 - val_mae: 51.9066\n",
            "Epoch 185/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6099 - mae: 49.6146 - val_loss: 4480.7591 - val_mae: 51.9077\n",
            "Epoch 186/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6942 - mae: 49.6200 - val_loss: 4480.3044 - val_mae: 51.9083\n",
            "Epoch 187/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.8070 - mae: 49.6188 - val_loss: 4480.2383 - val_mae: 51.9084\n",
            "Epoch 188/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9087 - mae: 49.6281 - val_loss: 4479.2483 - val_mae: 51.9098\n",
            "Epoch 189/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.1049 - mae: 49.6330 - val_loss: 4478.3302 - val_mae: 51.9110\n",
            "Epoch 190/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.8444 - mae: 49.6240 - val_loss: 4480.5322 - val_mae: 51.9080\n",
            "Epoch 191/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6349 - mae: 49.6191 - val_loss: 4479.6011 - val_mae: 51.9093\n",
            "Epoch 192/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9758 - mae: 49.6329 - val_loss: 4478.2059 - val_mae: 51.9112\n",
            "Epoch 193/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7987 - mae: 49.6237 - val_loss: 4479.8613 - val_mae: 51.9089\n",
            "Epoch 194/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6469 - mae: 49.6229 - val_loss: 4479.8501 - val_mae: 51.9090\n",
            "Epoch 195/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.1088 - mae: 49.6280 - val_loss: 4479.5358 - val_mae: 51.9094\n",
            "Epoch 196/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6359 - mae: 49.6254 - val_loss: 4478.8600 - val_mae: 51.9103\n",
            "Epoch 197/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.7879 - mae: 49.6246 - val_loss: 4479.3054 - val_mae: 51.9097\n",
            "Epoch 198/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6938 - mae: 49.6213 - val_loss: 4479.8133 - val_mae: 51.9090\n",
            "Epoch 199/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6006 - mae: 49.6233 - val_loss: 4479.0841 - val_mae: 51.9100\n",
            "Epoch 200/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6405 - mae: 49.6271 - val_loss: 4478.6978 - val_mae: 51.9105\n",
            "Epoch 201/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6872 - mae: 49.6264 - val_loss: 4478.6108 - val_mae: 51.9106\n",
            "Epoch 202/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6898 - mae: 49.6253 - val_loss: 4479.6192 - val_mae: 51.9093\n",
            "Epoch 203/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7033 - mae: 49.6279 - val_loss: 4478.6481 - val_mae: 51.9106\n",
            "Epoch 204/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7165 - mae: 49.6243 - val_loss: 4479.9771 - val_mae: 51.9088\n",
            "Epoch 205/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7799 - mae: 49.6204 - val_loss: 4479.7347 - val_mae: 51.9091\n",
            "Epoch 206/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6095 - mae: 49.6248 - val_loss: 4479.1020 - val_mae: 51.9100\n",
            "Epoch 207/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.7182 - mae: 49.6227 - val_loss: 4479.9190 - val_mae: 51.9089\n",
            "Epoch 208/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7407 - mae: 49.6249 - val_loss: 4479.2435 - val_mae: 51.9098\n",
            "Epoch 209/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7453 - mae: 49.6242 - val_loss: 4480.0142 - val_mae: 51.9087\n",
            "Epoch 210/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9667 - mae: 49.6304 - val_loss: 4478.6364 - val_mae: 51.9106\n",
            "Epoch 211/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.0098 - mae: 49.6326 - val_loss: 4477.6697 - val_mae: 51.9119\n",
            "Epoch 212/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4053.0029 - mae: 49.6289 - val_loss: 4480.2507 - val_mae: 51.9084\n",
            "Epoch 213/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6560 - mae: 49.6260 - val_loss: 4478.4515 - val_mae: 51.9109\n",
            "Epoch 214/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6877 - mae: 49.6303 - val_loss: 4479.2489 - val_mae: 51.9098\n",
            "Epoch 215/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6119 - mae: 49.6281 - val_loss: 4478.2859 - val_mae: 51.9111\n",
            "Epoch 216/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7697 - mae: 49.6360 - val_loss: 4477.2153 - val_mae: 51.9126\n",
            "Epoch 217/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6936 - mae: 49.6366 - val_loss: 4478.2953 - val_mae: 51.9111\n",
            "Epoch 218/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.8233 - mae: 49.6304 - val_loss: 4478.7780 - val_mae: 51.9104\n",
            "Epoch 219/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7505 - mae: 49.6271 - val_loss: 4479.3445 - val_mae: 51.9096\n",
            "Epoch 220/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6360 - mae: 49.6246 - val_loss: 4479.1135 - val_mae: 51.9099\n",
            "Epoch 221/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6056 - mae: 49.6250 - val_loss: 4479.0665 - val_mae: 51.9100\n",
            "Epoch 222/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4053.0900 - mae: 49.6354 - val_loss: 4477.5770 - val_mae: 51.9121\n",
            "Epoch 223/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.3047 - mae: 49.6479 - val_loss: 4477.0005 - val_mae: 51.9129\n",
            "Epoch 224/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7280 - mae: 49.6293 - val_loss: 4479.7056 - val_mae: 51.9091\n",
            "Epoch 225/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6760 - mae: 49.6243 - val_loss: 4479.0920 - val_mae: 51.9100\n",
            "Epoch 226/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.7213 - mae: 49.6285 - val_loss: 4478.8919 - val_mae: 51.9103\n",
            "Epoch 227/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.7120 - mae: 49.6301 - val_loss: 4478.2384 - val_mae: 51.9111\n",
            "Epoch 228/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6138 - mae: 49.6292 - val_loss: 4479.0660 - val_mae: 51.9100\n",
            "Epoch 229/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7028 - mae: 49.6271 - val_loss: 4479.5546 - val_mae: 51.9093\n",
            "Epoch 230/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.0191 - mae: 49.6340 - val_loss: 4478.1927 - val_mae: 51.9112\n",
            "Epoch 231/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.8544 - mae: 49.6378 - val_loss: 4478.1303 - val_mae: 51.9113\n",
            "Epoch 232/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.8321 - mae: 49.6291 - val_loss: 4479.6222 - val_mae: 51.9093\n",
            "Epoch 233/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.1623 - mae: 49.6311 - val_loss: 4477.6845 - val_mae: 51.9119\n",
            "Epoch 234/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6722 - mae: 49.6261 - val_loss: 4479.7090 - val_mae: 51.9091\n",
            "Epoch 235/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7848 - mae: 49.6190 - val_loss: 4479.9570 - val_mae: 51.9088\n",
            "Epoch 236/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.9379 - mae: 49.6204 - val_loss: 4480.7774 - val_mae: 51.9077\n",
            "Epoch 237/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.2082 - mae: 49.6353 - val_loss: 4477.5050 - val_mae: 51.9122\n",
            "Epoch 238/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.4293 - mae: 49.6216 - val_loss: 4481.1484 - val_mae: 51.9072\n",
            "Epoch 239/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7654 - mae: 49.6223 - val_loss: 4478.1946 - val_mae: 51.9112\n",
            "Epoch 240/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.8091 - mae: 49.6345 - val_loss: 4478.6736 - val_mae: 51.9106\n",
            "Epoch 241/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9102 - mae: 49.6234 - val_loss: 4479.8584 - val_mae: 51.9089\n",
            "Epoch 242/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.7649 - mae: 49.6324 - val_loss: 4478.1733 - val_mae: 51.9112\n",
            "Epoch 243/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.3358 - mae: 49.6225 - val_loss: 4480.4997 - val_mae: 51.9081\n",
            "Epoch 244/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9590 - mae: 49.6278 - val_loss: 4479.2264 - val_mae: 51.9098\n",
            "Epoch 245/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9405 - mae: 49.6358 - val_loss: 4478.4479 - val_mae: 51.9109\n",
            "Epoch 246/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9805 - mae: 49.6262 - val_loss: 4480.5540 - val_mae: 51.9080\n",
            "Epoch 247/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.0004 - mae: 49.6284 - val_loss: 4477.4502 - val_mae: 51.9122\n",
            "Epoch 248/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.7272 - mae: 49.6396 - val_loss: 4476.8013 - val_mae: 51.9131\n",
            "Epoch 249/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.7395 - mae: 49.6328 - val_loss: 4478.3362 - val_mae: 51.9110\n",
            "Epoch 250/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.8286 - mae: 49.6360 - val_loss: 4478.4174 - val_mae: 51.9109\n",
            "Epoch 251/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.7396 - mae: 49.6327 - val_loss: 4477.5841 - val_mae: 51.9120\n",
            "Epoch 252/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.8527 - mae: 49.6276 - val_loss: 4479.1618 - val_mae: 51.9099\n",
            "Epoch 253/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.8305 - mae: 49.6368 - val_loss: 4477.7516 - val_mae: 51.9118\n",
            "Epoch 254/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.6591 - mae: 49.6282 - val_loss: 4479.0482 - val_mae: 51.9100\n",
            "Epoch 255/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.8193 - mae: 49.6232 - val_loss: 4479.7678 - val_mae: 51.9091\n",
            "Epoch 256/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.9455 - mae: 49.6301 - val_loss: 4479.3741 - val_mae: 51.9096\n",
            "Epoch 257/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.0613 - mae: 49.6287 - val_loss: 4478.6250 - val_mae: 51.9106\n",
            "Epoch 258/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.7832 - mae: 49.6231 - val_loss: 4482.1220 - val_mae: 51.9059\n",
            "Epoch 259/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.1219 - mae: 49.6306 - val_loss: 4478.6083 - val_mae: 51.9106\n",
            "Epoch 260/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.1092 - mae: 49.6316 - val_loss: 4479.9929 - val_mae: 51.9088\n",
            "Epoch 261/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.1843 - mae: 49.6374 - val_loss: 4477.6487 - val_mae: 51.9120\n",
            "Epoch 262/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4052.6960 - mae: 49.6378 - val_loss: 4477.8045 - val_mae: 51.9114\n",
            "Epoch 263/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 4053.6051 - mae: 49.6171 - val_loss: 4481.0907 - val_mae: 51.9068\n",
            "Epoch 264/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4052.8214 - mae: 49.6029 - val_loss: 4482.3015 - val_mae: 51.9016\n",
            "Epoch 265/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 4051.4342 - mae: 49.6143 - val_loss: 4473.6285 - val_mae: 51.8653\n",
            "Epoch 266/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 3934.6875 - mae: 48.5868 - val_loss: 3900.7856 - val_mae: 45.7158\n",
            "Epoch 267/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 2776.7203 - mae: 32.2926 - val_loss: 3209.1229 - val_mae: 33.3959\n",
            "Epoch 268/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 2454.8573 - mae: 26.5639 - val_loss: 2985.8077 - val_mae: 30.4665\n",
            "Epoch 269/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 2290.8600 - mae: 24.5065 - val_loss: 2812.2918 - val_mae: 28.1046\n",
            "Epoch 270/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 2158.7316 - mae: 23.1739 - val_loss: 2654.8502 - val_mae: 26.6827\n",
            "Epoch 271/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 2038.6838 - mae: 21.9733 - val_loss: 2515.9071 - val_mae: 25.7465\n",
            "Epoch 272/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 1930.5195 - mae: 21.0389 - val_loss: 2401.2919 - val_mae: 25.0396\n",
            "Epoch 273/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 1839.1502 - mae: 20.7197 - val_loss: 2287.0761 - val_mae: 24.1155\n",
            "Epoch 274/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 1752.9873 - mae: 19.8642 - val_loss: 2176.4874 - val_mae: 22.8825\n",
            "Epoch 275/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 1669.8890 - mae: 19.1322 - val_loss: 2086.0416 - val_mae: 22.5882\n",
            "Epoch 276/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 1596.9494 - mae: 18.4589 - val_loss: 1994.0458 - val_mae: 21.4730\n",
            "Epoch 277/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 1527.3611 - mae: 17.9369 - val_loss: 1921.4102 - val_mae: 21.6000\n",
            "Epoch 278/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 1463.1124 - mae: 17.1386 - val_loss: 1837.3341 - val_mae: 20.1934\n",
            "Epoch 279/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 1404.2599 - mae: 16.7862 - val_loss: 1768.5007 - val_mae: 19.7374\n",
            "Epoch 280/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 1349.9789 - mae: 16.1770 - val_loss: 1701.0016 - val_mae: 19.4701\n",
            "Epoch 281/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 1294.1826 - mae: 15.5691 - val_loss: 1638.9798 - val_mae: 18.6165\n",
            "Epoch 282/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 1249.2583 - mae: 15.3701 - val_loss: 1578.4012 - val_mae: 18.2411\n",
            "Epoch 283/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 1212.1852 - mae: 15.7592 - val_loss: 1538.7280 - val_mae: 19.5423\n",
            "Epoch 284/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 1161.8343 - mae: 14.8183 - val_loss: 1469.7728 - val_mae: 17.5426\n",
            "Epoch 285/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 1116.5948 - mae: 14.0144 - val_loss: 1419.9980 - val_mae: 16.8948\n",
            "Epoch 286/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 1080.6996 - mae: 13.8634 - val_loss: 1370.9336 - val_mae: 16.6445\n",
            "Epoch 287/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 1044.9038 - mae: 13.6604 - val_loss: 1334.6286 - val_mae: 17.1959\n",
            "Epoch 288/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 1013.5523 - mae: 13.8097 - val_loss: 1284.7252 - val_mae: 16.1461\n",
            "Epoch 289/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 977.7780 - mae: 13.2433 - val_loss: 1242.2310 - val_mae: 15.7650\n",
            "Epoch 290/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 945.1381 - mae: 12.8458 - val_loss: 1201.6290 - val_mae: 15.2841\n",
            "Epoch 291/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 914.6957 - mae: 12.6337 - val_loss: 1164.2035 - val_mae: 15.1530\n",
            "Epoch 292/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 886.6534 - mae: 12.3383 - val_loss: 1126.1447 - val_mae: 14.8293\n",
            "Epoch 293/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 856.8833 - mae: 11.9409 - val_loss: 1091.6973 - val_mae: 14.5120\n",
            "Epoch 294/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 830.6130 - mae: 11.8097 - val_loss: 1059.8681 - val_mae: 14.3435\n",
            "Epoch 295/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 808.2774 - mae: 11.9331 - val_loss: 1025.9754 - val_mae: 13.9888\n",
            "Epoch 296/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 782.3449 - mae: 11.5720 - val_loss: 996.2031 - val_mae: 13.8564\n",
            "Epoch 297/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 760.0588 - mae: 11.5437 - val_loss: 961.1708 - val_mae: 13.3025\n",
            "Epoch 298/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 734.8611 - mae: 11.2325 - val_loss: 938.2478 - val_mae: 13.5327\n",
            "Epoch 299/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 713.6451 - mae: 11.0005 - val_loss: 909.3124 - val_mae: 13.3603\n",
            "Epoch 300/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 691.7883 - mae: 10.7985 - val_loss: 880.7972 - val_mae: 12.8539\n",
            "Epoch 301/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 670.6679 - mae: 10.5449 - val_loss: 854.9136 - val_mae: 12.6764\n",
            "Epoch 302/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 651.8761 - mae: 10.4678 - val_loss: 827.2057 - val_mae: 12.2142\n",
            "Epoch 303/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 631.3524 - mae: 10.1508 - val_loss: 802.7685 - val_mae: 11.9903\n",
            "Epoch 304/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 613.3787 - mae: 10.0452 - val_loss: 780.0129 - val_mae: 11.9461\n",
            "Epoch 305/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 595.8154 - mae: 9.8889 - val_loss: 758.0385 - val_mae: 11.9266\n",
            "Epoch 306/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 579.6600 - mae: 9.9610 - val_loss: 737.2240 - val_mae: 11.7594\n",
            "Epoch 307/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 566.8174 - mae: 10.1584 - val_loss: 721.6372 - val_mae: 12.4201\n",
            "Epoch 308/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 546.5236 - mae: 9.4948 - val_loss: 693.9032 - val_mae: 11.1718\n",
            "Epoch 309/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 530.6157 - mae: 9.2572 - val_loss: 678.0305 - val_mae: 11.3516\n",
            "Epoch 310/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 517.4133 - mae: 9.5000 - val_loss: 666.4418 - val_mae: 11.8955\n",
            "Epoch 311/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 510.2823 - mae: 10.0505 - val_loss: 645.7436 - val_mae: 11.6791\n",
            "Epoch 312/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 490.6509 - mae: 9.3779 - val_loss: 618.6580 - val_mae: 10.5141\n",
            "Epoch 313/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 473.9111 - mae: 8.8308 - val_loss: 602.0294 - val_mae: 10.4790\n",
            "Epoch 314/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 463.0032 - mae: 8.9954 - val_loss: 585.9782 - val_mae: 10.4318\n",
            "Epoch 315/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 448.8613 - mae: 8.6465 - val_loss: 572.4063 - val_mae: 10.1875\n",
            "Epoch 316/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 440.0281 - mae: 8.7488 - val_loss: 560.5081 - val_mae: 10.6989\n",
            "Epoch 317/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 426.8996 - mae: 8.6957 - val_loss: 540.3521 - val_mae: 9.8001\n",
            "Epoch 318/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 413.4058 - mae: 8.2117 - val_loss: 524.1528 - val_mae: 9.7161\n",
            "Epoch 319/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 402.6062 - mae: 8.2249 - val_loss: 511.4686 - val_mae: 9.5312\n",
            "Epoch 320/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 392.5500 - mae: 8.1715 - val_loss: 499.0687 - val_mae: 9.6215\n",
            "Epoch 321/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 383.7882 - mae: 8.2341 - val_loss: 487.0678 - val_mae: 9.4526\n",
            "Epoch 322/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 375.9682 - mae: 8.2377 - val_loss: 475.2816 - val_mae: 9.5944\n",
            "Epoch 323/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 362.9999 - mae: 7.8321 - val_loss: 460.7574 - val_mae: 9.2767\n",
            "Epoch 324/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 352.6678 - mae: 7.6859 - val_loss: 447.5561 - val_mae: 8.8654\n",
            "Epoch 325/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 342.5938 - mae: 7.5608 - val_loss: 439.9335 - val_mae: 9.2156\n",
            "Epoch 326/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 335.5903 - mae: 7.6805 - val_loss: 429.8963 - val_mae: 9.3256\n",
            "Epoch 327/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 327.5506 - mae: 7.6292 - val_loss: 417.3387 - val_mae: 8.5451\n",
            "Epoch 328/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 316.7797 - mae: 7.1994 - val_loss: 401.7090 - val_mae: 8.2529\n",
            "Epoch 329/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 307.4367 - mae: 7.1107 - val_loss: 393.2781 - val_mae: 8.3789\n",
            "Epoch 330/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 301.7772 - mae: 7.3427 - val_loss: 385.0120 - val_mae: 8.4195\n",
            "Epoch 331/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 298.1031 - mae: 7.5975 - val_loss: 380.0879 - val_mae: 8.5383\n",
            "Epoch 332/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 288.4744 - mae: 7.3212 - val_loss: 363.5555 - val_mae: 7.9059\n",
            "Epoch 333/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 278.9992 - mae: 6.9975 - val_loss: 355.2099 - val_mae: 7.8755\n",
            "Epoch 334/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 269.8966 - mae: 6.6939 - val_loss: 347.3184 - val_mae: 7.7506\n",
            "Epoch 335/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 266.4425 - mae: 6.9213 - val_loss: 337.3087 - val_mae: 7.5869\n",
            "Epoch 336/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 257.2209 - mae: 6.6280 - val_loss: 329.1367 - val_mae: 7.6221\n",
            "Epoch 337/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 251.2411 - mae: 6.6117 - val_loss: 321.6734 - val_mae: 7.4064\n",
            "Epoch 338/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 245.5799 - mae: 6.5002 - val_loss: 313.5527 - val_mae: 7.3235\n",
            "Epoch 339/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 241.4029 - mae: 6.7980 - val_loss: 307.5222 - val_mae: 7.5032\n",
            "Epoch 340/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 234.1794 - mae: 6.5216 - val_loss: 299.3797 - val_mae: 7.2213\n",
            "Epoch 341/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 226.4104 - mae: 6.2403 - val_loss: 289.6964 - val_mae: 6.9161\n",
            "Epoch 342/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 220.9132 - mae: 6.1978 - val_loss: 289.5348 - val_mae: 7.2953\n",
            "Epoch 343/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 218.1539 - mae: 6.3375 - val_loss: 276.7689 - val_mae: 6.9126\n",
            "Epoch 344/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 212.4559 - mae: 6.2652 - val_loss: 271.7204 - val_mae: 6.7659\n",
            "Epoch 345/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 206.1391 - mae: 5.9945 - val_loss: 264.4177 - val_mae: 6.7594\n",
            "Epoch 346/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 203.9026 - mae: 6.3730 - val_loss: 268.1827 - val_mae: 7.9344\n",
            "Epoch 347/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 198.1996 - mae: 6.2461 - val_loss: 253.6177 - val_mae: 6.9458\n",
            "Epoch 348/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 192.1988 - mae: 5.9140 - val_loss: 251.5045 - val_mae: 6.7837\n",
            "Epoch 349/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 189.5790 - mae: 6.0478 - val_loss: 252.6775 - val_mae: 7.0865\n",
            "Epoch 350/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 189.9125 - mae: 6.5290 - val_loss: 235.5051 - val_mae: 6.6035\n",
            "Epoch 351/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 181.4166 - mae: 5.9579 - val_loss: 230.4786 - val_mae: 6.5975\n",
            "Epoch 352/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 174.2084 - mae: 5.6893 - val_loss: 229.5855 - val_mae: 6.4711\n",
            "Epoch 353/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 172.2771 - mae: 5.9227 - val_loss: 220.7541 - val_mae: 6.5014\n",
            "Epoch 354/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 170.1157 - mae: 6.0086 - val_loss: 213.4973 - val_mae: 6.1301\n",
            "Epoch 355/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 161.7046 - mae: 5.4636 - val_loss: 210.3949 - val_mae: 6.1467\n",
            "Epoch 356/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 158.9430 - mae: 5.4776 - val_loss: 213.2158 - val_mae: 6.5359\n",
            "Epoch 357/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 157.8549 - mae: 5.6767 - val_loss: 202.4215 - val_mae: 6.2250\n",
            "Epoch 358/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 152.6345 - mae: 5.5113 - val_loss: 196.1728 - val_mae: 6.0002\n",
            "Epoch 359/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 149.9040 - mae: 5.4856 - val_loss: 191.3583 - val_mae: 5.9158\n",
            "Epoch 360/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 145.0653 - mae: 5.3204 - val_loss: 196.9573 - val_mae: 6.3741\n",
            "Epoch 361/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 144.1430 - mae: 5.4627 - val_loss: 187.6389 - val_mae: 6.5050\n",
            "Epoch 362/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 145.0730 - mae: 5.9340 - val_loss: 183.3322 - val_mae: 6.2711\n",
            "Epoch 363/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 137.8778 - mae: 5.4841 - val_loss: 175.4389 - val_mae: 5.6729\n",
            "Epoch 364/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 133.5223 - mae: 5.3482 - val_loss: 184.8651 - val_mae: 6.2531\n",
            "Epoch 365/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 131.6882 - mae: 5.3989 - val_loss: 169.8833 - val_mae: 5.8672\n",
            "Epoch 366/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 128.5043 - mae: 5.1552 - val_loss: 165.6324 - val_mae: 5.5908\n",
            "Epoch 367/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 127.2739 - mae: 5.1310 - val_loss: 173.4821 - val_mae: 6.3686\n",
            "Epoch 368/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 124.3888 - mae: 5.3354 - val_loss: 159.2046 - val_mae: 5.7700\n",
            "Epoch 369/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 122.2804 - mae: 5.1509 - val_loss: 153.0303 - val_mae: 5.2247\n",
            "Epoch 370/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 118.3010 - mae: 5.0761 - val_loss: 152.9908 - val_mae: 5.4713\n",
            "Epoch 371/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 114.0016 - mae: 4.8784 - val_loss: 148.2376 - val_mae: 5.3368\n",
            "Epoch 372/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 112.2115 - mae: 4.9443 - val_loss: 153.3899 - val_mae: 5.7581\n",
            "Epoch 373/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 111.1762 - mae: 4.9092 - val_loss: 149.1371 - val_mae: 5.5705\n",
            "Epoch 374/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 108.8263 - mae: 4.9000 - val_loss: 147.4556 - val_mae: 5.8612\n",
            "Epoch 375/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 108.3465 - mae: 4.9926 - val_loss: 139.8816 - val_mae: 5.5101\n",
            "Epoch 376/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 105.6012 - mae: 4.9048 - val_loss: 136.9817 - val_mae: 5.5830\n",
            "Epoch 377/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 102.7927 - mae: 4.7888 - val_loss: 134.6863 - val_mae: 5.2143\n",
            "Epoch 378/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 99.0718 - mae: 4.6507 - val_loss: 128.1498 - val_mae: 5.0223\n",
            "Epoch 379/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 100.7732 - mae: 4.8782 - val_loss: 134.9584 - val_mae: 5.9941\n",
            "Epoch 380/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 96.6116 - mae: 4.8297 - val_loss: 124.5261 - val_mae: 5.1791\n",
            "Epoch 381/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 94.4886 - mae: 4.6461 - val_loss: 126.8626 - val_mae: 5.7702\n",
            "Epoch 382/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 93.7563 - mae: 4.6697 - val_loss: 119.8183 - val_mae: 5.0373\n",
            "Epoch 383/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 93.2443 - mae: 4.7871 - val_loss: 119.3544 - val_mae: 5.0521\n",
            "Epoch 384/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 93.0547 - mae: 4.9021 - val_loss: 115.9905 - val_mae: 5.1802\n",
            "Epoch 385/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 89.3657 - mae: 4.6772 - val_loss: 122.4722 - val_mae: 5.3694\n",
            "Epoch 386/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 85.9448 - mae: 4.4428 - val_loss: 111.2493 - val_mae: 4.8538\n",
            "Epoch 387/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 85.4521 - mae: 4.4510 - val_loss: 111.4455 - val_mae: 4.8814\n",
            "Epoch 388/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 84.7261 - mae: 4.4123 - val_loss: 107.1981 - val_mae: 4.8287\n",
            "Epoch 389/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 82.5616 - mae: 4.4520 - val_loss: 105.8082 - val_mae: 4.7058\n",
            "Epoch 390/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 82.7419 - mae: 4.5722 - val_loss: 105.2774 - val_mae: 5.1111\n",
            "Epoch 391/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 79.7527 - mae: 4.4241 - val_loss: 100.4258 - val_mae: 4.5629\n",
            "Epoch 392/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 77.9706 - mae: 4.3396 - val_loss: 101.0250 - val_mae: 4.7246\n",
            "Epoch 393/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 76.1196 - mae: 4.1438 - val_loss: 98.2428 - val_mae: 4.5511\n",
            "Epoch 394/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 74.2854 - mae: 4.1856 - val_loss: 97.3184 - val_mae: 4.7225\n",
            "Epoch 395/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 73.2237 - mae: 4.1396 - val_loss: 96.4491 - val_mae: 4.6360\n",
            "Epoch 396/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 72.5261 - mae: 4.1758 - val_loss: 93.6024 - val_mae: 4.4490\n",
            "Epoch 397/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 71.8481 - mae: 4.2076 - val_loss: 95.0434 - val_mae: 4.9945\n",
            "Epoch 398/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 71.7474 - mae: 4.2852 - val_loss: 90.5281 - val_mae: 4.4522\n",
            "Epoch 399/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 70.0763 - mae: 4.2013 - val_loss: 89.9355 - val_mae: 4.4004\n",
            "Epoch 400/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 66.8808 - mae: 3.9594 - val_loss: 91.0293 - val_mae: 5.0187\n",
            "Epoch 401/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 68.1048 - mae: 4.1819 - val_loss: 90.7080 - val_mae: 5.0040\n",
            "Epoch 402/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 64.3073 - mae: 3.9764 - val_loss: 84.5098 - val_mae: 4.3123\n",
            "Epoch 403/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 64.4427 - mae: 4.0050 - val_loss: 83.5731 - val_mae: 4.3025\n",
            "Epoch 404/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 63.3725 - mae: 4.0130 - val_loss: 86.6275 - val_mae: 4.5086\n",
            "Epoch 405/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 61.5010 - mae: 3.9340 - val_loss: 90.9459 - val_mae: 4.8535\n",
            "Epoch 406/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 65.0679 - mae: 4.2708 - val_loss: 80.3664 - val_mae: 4.2045\n",
            "Epoch 407/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 62.8687 - mae: 4.1704 - val_loss: 79.1993 - val_mae: 4.2606\n",
            "Epoch 408/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 68.1546 - mae: 4.5220 - val_loss: 79.7554 - val_mae: 4.2745\n",
            "Epoch 409/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 60.5333 - mae: 3.9927 - val_loss: 82.3443 - val_mae: 4.8771\n",
            "Epoch 410/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 59.5672 - mae: 3.9769 - val_loss: 74.7148 - val_mae: 4.0655\n",
            "Epoch 411/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 56.9889 - mae: 3.8263 - val_loss: 75.8201 - val_mae: 4.3341\n",
            "Epoch 412/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 56.4028 - mae: 3.8034 - val_loss: 72.8897 - val_mae: 3.9559\n",
            "Epoch 413/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 55.1640 - mae: 3.7710 - val_loss: 72.0801 - val_mae: 4.1100\n",
            "Epoch 414/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 57.0637 - mae: 3.8556 - val_loss: 73.8472 - val_mae: 4.1956\n",
            "Epoch 415/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 53.5965 - mae: 3.7656 - val_loss: 70.0729 - val_mae: 4.0070\n",
            "Epoch 416/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 53.5608 - mae: 3.8065 - val_loss: 70.1240 - val_mae: 4.0810\n",
            "Epoch 417/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 57.7257 - mae: 4.3172 - val_loss: 71.2162 - val_mae: 4.2498\n",
            "Epoch 418/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 56.0962 - mae: 4.2881 - val_loss: 71.0920 - val_mae: 4.3510\n",
            "Epoch 419/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 55.0208 - mae: 3.9719 - val_loss: 71.4226 - val_mae: 4.5736\n",
            "Epoch 420/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 53.2875 - mae: 3.9458 - val_loss: 69.0049 - val_mae: 4.2754\n",
            "Epoch 421/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 52.3483 - mae: 3.9702 - val_loss: 70.8906 - val_mae: 4.2724\n",
            "Epoch 422/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 50.2228 - mae: 3.7903 - val_loss: 65.6219 - val_mae: 3.8616\n",
            "Epoch 423/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 50.9204 - mae: 3.8806 - val_loss: 64.5258 - val_mae: 3.8652\n",
            "Epoch 424/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 47.7577 - mae: 3.6476 - val_loss: 67.5384 - val_mae: 4.2441\n",
            "Epoch 425/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 50.8062 - mae: 3.8600 - val_loss: 65.7253 - val_mae: 4.3075\n",
            "Epoch 426/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 49.4649 - mae: 3.8706 - val_loss: 68.9694 - val_mae: 4.7372\n",
            "Epoch 427/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 49.1833 - mae: 3.9641 - val_loss: 63.3599 - val_mae: 4.0059\n",
            "Epoch 428/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 46.3437 - mae: 3.6094 - val_loss: 60.0994 - val_mae: 3.7985\n",
            "Epoch 429/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 46.5780 - mae: 3.7194 - val_loss: 62.1380 - val_mae: 3.9726\n",
            "Epoch 430/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 47.7783 - mae: 3.7541 - val_loss: 61.7748 - val_mae: 4.0147\n",
            "Epoch 431/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 45.8316 - mae: 3.6893 - val_loss: 61.0286 - val_mae: 4.1215\n",
            "Epoch 432/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 46.1850 - mae: 3.7310 - val_loss: 62.6804 - val_mae: 4.1089\n",
            "Epoch 433/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 46.0091 - mae: 3.7330 - val_loss: 60.9779 - val_mae: 4.1437\n",
            "Epoch 434/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 47.6634 - mae: 3.8232 - val_loss: 59.2724 - val_mae: 3.9135\n",
            "Epoch 435/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 44.9901 - mae: 3.6631 - val_loss: 62.7998 - val_mae: 4.2887\n",
            "Epoch 436/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 44.2633 - mae: 3.6939 - val_loss: 56.4171 - val_mae: 3.9008\n",
            "Epoch 437/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 45.3541 - mae: 3.9993 - val_loss: 58.4312 - val_mae: 4.2273\n",
            "Epoch 438/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 43.5498 - mae: 3.7001 - val_loss: 56.0083 - val_mae: 3.7527\n",
            "Epoch 439/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 43.1484 - mae: 3.6436 - val_loss: 54.9346 - val_mae: 3.8602\n",
            "Epoch 440/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 43.6555 - mae: 3.7537 - val_loss: 54.2765 - val_mae: 3.7917\n",
            "Epoch 441/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 43.1193 - mae: 3.6980 - val_loss: 55.6717 - val_mae: 3.8887\n",
            "Epoch 442/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 44.9576 - mae: 4.0205 - val_loss: 58.6501 - val_mae: 4.3025\n",
            "Epoch 443/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 41.6481 - mae: 3.6011 - val_loss: 51.0867 - val_mae: 3.6650\n",
            "Epoch 444/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 40.7953 - mae: 3.5524 - val_loss: 54.3991 - val_mae: 3.9134\n",
            "Epoch 445/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 39.5567 - mae: 3.4260 - val_loss: 51.6642 - val_mae: 3.7742\n",
            "Epoch 446/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 40.5116 - mae: 3.5919 - val_loss: 52.0904 - val_mae: 3.7596\n",
            "Epoch 447/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 41.3926 - mae: 3.7169 - val_loss: 53.5328 - val_mae: 3.8081\n",
            "Epoch 448/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 42.2580 - mae: 3.7152 - val_loss: 51.0021 - val_mae: 3.7601\n",
            "Epoch 449/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 38.8500 - mae: 3.5244 - val_loss: 47.6276 - val_mae: 3.6212\n",
            "Epoch 450/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 38.2399 - mae: 3.4317 - val_loss: 47.8045 - val_mae: 3.7199\n",
            "Epoch 451/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 39.4237 - mae: 3.5811 - val_loss: 51.0224 - val_mae: 3.9346\n",
            "Epoch 452/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 40.4162 - mae: 3.8199 - val_loss: 50.6742 - val_mae: 4.0413\n",
            "Epoch 453/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 39.3092 - mae: 3.5904 - val_loss: 54.0052 - val_mae: 4.2330\n",
            "Epoch 454/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 40.6881 - mae: 3.7214 - val_loss: 48.9509 - val_mae: 3.8419\n",
            "Epoch 455/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 37.7381 - mae: 3.4956 - val_loss: 46.3390 - val_mae: 3.6297\n",
            "Epoch 456/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 36.6366 - mae: 3.4342 - val_loss: 45.5975 - val_mae: 3.5577\n",
            "Epoch 457/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 37.8946 - mae: 3.6091 - val_loss: 44.7634 - val_mae: 3.5532\n",
            "Epoch 458/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 38.1571 - mae: 3.6414 - val_loss: 49.0240 - val_mae: 3.8848\n",
            "Epoch 459/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 36.0780 - mae: 3.3366 - val_loss: 44.5754 - val_mae: 3.6197\n",
            "Epoch 460/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 36.2043 - mae: 3.5300 - val_loss: 50.9476 - val_mae: 4.0561\n",
            "Epoch 461/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 37.7252 - mae: 3.6910 - val_loss: 43.7319 - val_mae: 3.5570\n",
            "Epoch 462/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 34.3877 - mae: 3.2889 - val_loss: 43.5307 - val_mae: 3.5031\n",
            "Epoch 463/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 34.7737 - mae: 3.3951 - val_loss: 46.8062 - val_mae: 3.8588\n",
            "Epoch 464/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 36.0211 - mae: 3.5637 - val_loss: 41.1916 - val_mae: 3.4389\n",
            "Epoch 465/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 35.7491 - mae: 3.5848 - val_loss: 44.9338 - val_mae: 4.0834\n",
            "Epoch 466/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 39.7019 - mae: 4.0111 - val_loss: 45.0920 - val_mae: 3.8647\n",
            "Epoch 467/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 37.4100 - mae: 3.5351 - val_loss: 43.6552 - val_mae: 3.6404\n",
            "Epoch 468/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 35.3969 - mae: 3.6096 - val_loss: 45.3119 - val_mae: 4.2174\n",
            "Epoch 469/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 33.8021 - mae: 3.4276 - val_loss: 40.7230 - val_mae: 3.5016\n",
            "Epoch 470/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 33.5618 - mae: 3.3191 - val_loss: 40.8058 - val_mae: 3.7336\n",
            "Epoch 471/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 37.6563 - mae: 3.6764 - val_loss: 41.3987 - val_mae: 3.5645\n",
            "Epoch 472/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 35.8732 - mae: 3.7738 - val_loss: 41.1152 - val_mae: 3.6235\n",
            "Epoch 473/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 33.2400 - mae: 3.4633 - val_loss: 42.1350 - val_mae: 3.8888\n",
            "Epoch 474/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 33.3849 - mae: 3.5138 - val_loss: 37.8456 - val_mae: 3.4422\n",
            "Epoch 475/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 32.7256 - mae: 3.4530 - val_loss: 38.3657 - val_mae: 3.5481\n",
            "Epoch 476/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 33.9396 - mae: 3.5814 - val_loss: 42.5497 - val_mae: 3.8427\n",
            "Epoch 477/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 34.6573 - mae: 3.6282 - val_loss: 37.2591 - val_mae: 3.3795\n",
            "Epoch 478/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 32.1368 - mae: 3.3340 - val_loss: 41.7898 - val_mae: 3.7680\n",
            "Epoch 479/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 32.1475 - mae: 3.5004 - val_loss: 41.8387 - val_mae: 3.9736\n",
            "Epoch 480/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 35.8840 - mae: 3.7160 - val_loss: 35.5799 - val_mae: 3.3371\n",
            "Epoch 481/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 33.2060 - mae: 3.5923 - val_loss: 41.3829 - val_mae: 4.2233\n",
            "Epoch 482/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 33.6462 - mae: 3.6550 - val_loss: 39.7580 - val_mae: 3.6540\n",
            "Epoch 483/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 32.5895 - mae: 3.4513 - val_loss: 36.0022 - val_mae: 3.3843\n",
            "Epoch 484/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 30.4585 - mae: 3.3113 - val_loss: 41.1331 - val_mae: 4.0841\n",
            "Epoch 485/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 32.6442 - mae: 3.6823 - val_loss: 36.1311 - val_mae: 3.3857\n",
            "Epoch 486/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 29.7730 - mae: 3.2896 - val_loss: 37.9596 - val_mae: 3.6959\n",
            "Epoch 487/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 29.6084 - mae: 3.3570 - val_loss: 33.6236 - val_mae: 3.2636\n",
            "Epoch 488/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 30.6343 - mae: 3.3290 - val_loss: 33.3961 - val_mae: 3.4380\n",
            "Epoch 489/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 30.1793 - mae: 3.3504 - val_loss: 35.5706 - val_mae: 3.4484\n",
            "Epoch 490/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 30.2519 - mae: 3.4738 - val_loss: 34.9244 - val_mae: 3.4278\n",
            "Epoch 491/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 30.7220 - mae: 3.3547 - val_loss: 35.3487 - val_mae: 3.4446\n",
            "Epoch 492/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 30.9568 - mae: 3.4783 - val_loss: 39.2165 - val_mae: 3.8488\n",
            "Epoch 493/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 31.2475 - mae: 3.6327 - val_loss: 36.8546 - val_mae: 3.6448\n",
            "Epoch 494/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.6438 - mae: 3.3280 - val_loss: 32.6861 - val_mae: 3.5098\n",
            "Epoch 495/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 31.1340 - mae: 3.6740 - val_loss: 34.9023 - val_mae: 3.8323\n",
            "Epoch 496/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.7724 - mae: 3.3140 - val_loss: 33.6454 - val_mae: 3.3603\n",
            "Epoch 497/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 27.0868 - mae: 3.2059 - val_loss: 36.8232 - val_mae: 3.7259\n",
            "Epoch 498/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 30.6423 - mae: 3.4425 - val_loss: 34.4617 - val_mae: 3.6159\n",
            "Epoch 499/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 33.1742 - mae: 3.7908 - val_loss: 35.5306 - val_mae: 3.6897\n",
            "Epoch 500/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 29.2648 - mae: 3.4990 - val_loss: 34.3183 - val_mae: 3.4584\n",
            "Epoch 501/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 33.5063 - mae: 3.9341 - val_loss: 35.8456 - val_mae: 3.7914\n",
            "Epoch 502/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 27.9826 - mae: 3.2758 - val_loss: 35.1144 - val_mae: 3.9744\n",
            "Epoch 503/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 31.6979 - mae: 3.7134 - val_loss: 32.4915 - val_mae: 3.4563\n",
            "Epoch 504/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 31.1998 - mae: 3.5800 - val_loss: 29.1345 - val_mae: 3.2218\n",
            "Epoch 505/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.1866 - mae: 3.3174 - val_loss: 33.7239 - val_mae: 3.8619\n",
            "Epoch 506/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 27.4798 - mae: 3.4115 - val_loss: 31.2514 - val_mae: 3.5644\n",
            "Epoch 507/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.6392 - mae: 3.3780 - val_loss: 30.0706 - val_mae: 3.3785\n",
            "Epoch 508/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.3453 - mae: 3.5093 - val_loss: 29.3238 - val_mae: 3.1603\n",
            "Epoch 509/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 29.7233 - mae: 3.5378 - val_loss: 33.1092 - val_mae: 3.7095\n",
            "Epoch 510/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 27.3374 - mae: 3.4044 - val_loss: 30.9911 - val_mae: 3.3462\n",
            "Epoch 511/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.1087 - mae: 3.3390 - val_loss: 29.5922 - val_mae: 3.4481\n",
            "Epoch 512/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 28.4702 - mae: 3.4619 - val_loss: 32.7035 - val_mae: 3.7845\n",
            "Epoch 513/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.1314 - mae: 3.4371 - val_loss: 28.6418 - val_mae: 3.2135\n",
            "Epoch 514/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.4767 - mae: 3.2738 - val_loss: 27.9565 - val_mae: 3.1983\n",
            "Epoch 515/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 25.1929 - mae: 3.0792 - val_loss: 28.7160 - val_mae: 3.4116\n",
            "Epoch 516/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 30.4517 - mae: 3.5908 - val_loss: 36.2903 - val_mae: 4.2613\n",
            "Epoch 517/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 32.7801 - mae: 3.7026 - val_loss: 33.5377 - val_mae: 3.6859\n",
            "Epoch 518/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.1353 - mae: 3.2973 - val_loss: 28.5957 - val_mae: 3.2973\n",
            "Epoch 519/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 27.0182 - mae: 3.3211 - val_loss: 26.4972 - val_mae: 3.1038\n",
            "Epoch 520/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.0231 - mae: 3.2313 - val_loss: 31.7892 - val_mae: 3.4232\n",
            "Epoch 521/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.6012 - mae: 3.3480 - val_loss: 28.2905 - val_mae: 3.2801\n",
            "Epoch 522/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.6988 - mae: 3.1293 - val_loss: 26.4413 - val_mae: 3.1168\n",
            "Epoch 523/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.4608 - mae: 3.1203 - val_loss: 26.2254 - val_mae: 3.1349\n",
            "Epoch 524/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.7433 - mae: 3.3263 - val_loss: 26.8850 - val_mae: 3.1422\n",
            "Epoch 525/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.1276 - mae: 3.2326 - val_loss: 26.4388 - val_mae: 3.1230\n",
            "Epoch 526/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.3428 - mae: 3.1348 - val_loss: 39.5579 - val_mae: 3.6171\n",
            "Epoch 527/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.0859 - mae: 3.1422 - val_loss: 27.5884 - val_mae: 3.3086\n",
            "Epoch 528/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 26.0170 - mae: 3.3700 - val_loss: 30.5755 - val_mae: 3.5206\n",
            "Epoch 529/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.6320 - mae: 3.2283 - val_loss: 32.7682 - val_mae: 3.8390\n",
            "Epoch 530/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.1923 - mae: 3.2734 - val_loss: 25.7908 - val_mae: 3.1695\n",
            "Epoch 531/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.5415 - mae: 3.2848 - val_loss: 26.6055 - val_mae: 3.3988\n",
            "Epoch 532/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.8236 - mae: 3.1425 - val_loss: 28.4930 - val_mae: 3.2995\n",
            "Epoch 533/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.9565 - mae: 3.3946 - val_loss: 30.1050 - val_mae: 3.8100\n",
            "Epoch 534/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.1956 - mae: 3.3376 - val_loss: 25.6310 - val_mae: 3.2816\n",
            "Epoch 535/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.4461 - mae: 3.3794 - val_loss: 23.9505 - val_mae: 2.9633\n",
            "Epoch 536/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 26.8070 - mae: 3.3440 - val_loss: 24.5686 - val_mae: 3.0706\n",
            "Epoch 537/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.3670 - mae: 3.1751 - val_loss: 31.1632 - val_mae: 3.5586\n",
            "Epoch 538/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 27.2054 - mae: 3.5612 - val_loss: 28.3487 - val_mae: 3.4803\n",
            "Epoch 539/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.5172 - mae: 3.1406 - val_loss: 23.6536 - val_mae: 3.0255\n",
            "Epoch 540/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.6112 - mae: 3.2802 - val_loss: 26.3295 - val_mae: 3.3547\n",
            "Epoch 541/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.5876 - mae: 3.3604 - val_loss: 23.1849 - val_mae: 3.0540\n",
            "Epoch 542/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.1971 - mae: 3.5629 - val_loss: 35.2784 - val_mae: 4.4945\n",
            "Epoch 543/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 27.5987 - mae: 3.5464 - val_loss: 28.4703 - val_mae: 3.4545\n",
            "Epoch 544/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.7211 - mae: 3.2343 - val_loss: 30.0819 - val_mae: 3.5045\n",
            "Epoch 545/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.4502 - mae: 3.0703 - val_loss: 23.5726 - val_mae: 3.0665\n",
            "Epoch 546/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.5619 - mae: 3.1065 - val_loss: 24.8968 - val_mae: 3.1978\n",
            "Epoch 547/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.9901 - mae: 3.1920 - val_loss: 24.5998 - val_mae: 3.3615\n",
            "Epoch 548/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.6225 - mae: 3.1428 - val_loss: 25.2419 - val_mae: 3.2079\n",
            "Epoch 549/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.6454 - mae: 3.1296 - val_loss: 24.8031 - val_mae: 3.1801\n",
            "Epoch 550/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.5228 - mae: 3.0948 - val_loss: 23.6483 - val_mae: 3.0226\n",
            "Epoch 551/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.8750 - mae: 3.1803 - val_loss: 23.2751 - val_mae: 3.0647\n",
            "Epoch 552/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 22.7762 - mae: 3.0028 - val_loss: 22.8420 - val_mae: 2.9851\n",
            "Epoch 553/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.6941 - mae: 3.4578 - val_loss: 22.8228 - val_mae: 3.0123\n",
            "Epoch 554/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.1510 - mae: 3.1129 - val_loss: 24.4871 - val_mae: 3.2300\n",
            "Epoch 555/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.2764 - mae: 3.2083 - val_loss: 28.4947 - val_mae: 3.6400\n",
            "Epoch 556/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.3920 - mae: 3.3863 - val_loss: 23.5744 - val_mae: 3.2348\n",
            "Epoch 557/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 22.8504 - mae: 3.1033 - val_loss: 22.4815 - val_mae: 3.0317\n",
            "Epoch 558/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.5818 - mae: 3.5044 - val_loss: 27.1047 - val_mae: 3.7055\n",
            "Epoch 559/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.1271 - mae: 3.2511 - val_loss: 22.2879 - val_mae: 3.0469\n",
            "Epoch 560/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 22.5578 - mae: 2.9868 - val_loss: 21.9511 - val_mae: 2.9880\n",
            "Epoch 561/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.1679 - mae: 3.0801 - val_loss: 23.4494 - val_mae: 3.0337\n",
            "Epoch 562/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.6663 - mae: 3.4712 - val_loss: 23.8212 - val_mae: 3.0908\n",
            "Epoch 563/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.1234 - mae: 3.3666 - val_loss: 26.6002 - val_mae: 3.5633\n",
            "Epoch 564/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.5211 - mae: 3.4575 - val_loss: 22.5908 - val_mae: 3.1616\n",
            "Epoch 565/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 26.1157 - mae: 3.4879 - val_loss: 22.8856 - val_mae: 3.1160\n",
            "Epoch 566/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.5091 - mae: 3.1124 - val_loss: 21.7894 - val_mae: 3.0277\n",
            "Epoch 567/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 24.1659 - mae: 3.2324 - val_loss: 21.8270 - val_mae: 3.0692\n",
            "Epoch 568/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.6925 - mae: 3.1439 - val_loss: 22.4882 - val_mae: 3.0632\n",
            "Epoch 569/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.2626 - mae: 3.4084 - val_loss: 38.4244 - val_mae: 4.3361\n",
            "Epoch 570/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 38.4342 - mae: 4.3422 - val_loss: 24.8078 - val_mae: 3.2438\n",
            "Epoch 571/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.1575 - mae: 3.2619 - val_loss: 22.4834 - val_mae: 3.1776\n",
            "Epoch 572/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.8368 - mae: 3.1998 - val_loss: 22.2938 - val_mae: 3.1395\n",
            "Epoch 573/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 26.6201 - mae: 3.4486 - val_loss: 23.4118 - val_mae: 3.2104\n",
            "Epoch 574/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 22.6304 - mae: 3.0925 - val_loss: 24.8082 - val_mae: 3.3861\n",
            "Epoch 575/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 24.8112 - mae: 3.2626 - val_loss: 23.5871 - val_mae: 3.3214\n",
            "Epoch 576/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 27.4338 - mae: 3.5123 - val_loss: 21.4554 - val_mae: 2.9833\n",
            "Epoch 577/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.4920 - mae: 3.3934 - val_loss: 23.2892 - val_mae: 3.2295\n",
            "Epoch 578/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.4510 - mae: 3.4582 - val_loss: 23.6818 - val_mae: 3.3963\n",
            "Epoch 579/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.9195 - mae: 3.3185 - val_loss: 25.4294 - val_mae: 3.5647\n",
            "Epoch 580/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.3502 - mae: 3.2068 - val_loss: 22.6441 - val_mae: 3.0403\n",
            "Epoch 581/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.3218 - mae: 3.0612 - val_loss: 20.5474 - val_mae: 2.9335\n",
            "Epoch 582/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.5299 - mae: 3.3929 - val_loss: 23.4070 - val_mae: 3.1621\n",
            "Epoch 583/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.7989 - mae: 3.5091 - val_loss: 25.9350 - val_mae: 3.5374\n",
            "Epoch 584/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 22.8252 - mae: 3.1133 - val_loss: 22.8316 - val_mae: 3.1321\n",
            "Epoch 585/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.1198 - mae: 3.2693 - val_loss: 26.3914 - val_mae: 3.6854\n",
            "Epoch 586/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 28.3545 - mae: 3.5470 - val_loss: 26.6698 - val_mae: 3.8749\n",
            "Epoch 587/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.9051 - mae: 3.2764 - val_loss: 23.7245 - val_mae: 3.3896\n",
            "Epoch 588/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 22.4797 - mae: 3.1063 - val_loss: 23.5268 - val_mae: 3.1681\n",
            "Epoch 589/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 22.1628 - mae: 2.9853 - val_loss: 21.3491 - val_mae: 2.9677\n",
            "Epoch 590/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.4856 - mae: 3.2127 - val_loss: 22.3937 - val_mae: 3.1255\n",
            "Epoch 591/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 21.8796 - mae: 3.0289 - val_loss: 22.7694 - val_mae: 3.1450\n",
            "Epoch 592/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 22.7512 - mae: 3.0608 - val_loss: 21.4427 - val_mae: 3.0493\n",
            "Epoch 593/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 22.3842 - mae: 3.0856 - val_loss: 20.2420 - val_mae: 2.9415\n",
            "Epoch 594/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.7389 - mae: 3.2519 - val_loss: 19.8874 - val_mae: 2.9679\n",
            "Epoch 595/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 24.7440 - mae: 3.3302 - val_loss: 27.0402 - val_mae: 3.7685\n",
            "Epoch 596/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 22.9228 - mae: 3.2293 - val_loss: 23.7368 - val_mae: 3.1703\n",
            "Epoch 597/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.1125 - mae: 3.0782 - val_loss: 22.0051 - val_mae: 3.0309\n",
            "Epoch 598/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 23.3191 - mae: 3.2063 - val_loss: 22.5708 - val_mae: 3.2930\n",
            "Epoch 599/600\n",
            "703/703 [==============================] - 1s 1ms/step - loss: 25.7819 - mae: 3.5368 - val_loss: 32.1253 - val_mae: 4.1688\n",
            "Epoch 600/600\n",
            "703/703 [==============================] - 1s 2ms/step - loss: 24.7408 - mae: 3.2669 - val_loss: 27.4565 - val_mae: 3.5221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cniNBLwMg0k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"./models/20834941_RNN_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNwhBEbqMU6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "3af1a946-f3ea-4ef3-e08f-ac1c8c010a5b"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['val_loss'],label=\"val loss\")\n",
        "  plt.plot(history.history['loss'],label=\"train loss\")\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('mae')\n",
        "\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}